{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import clip\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_MEAN = np.load(\"data/global_mean.npy\")/255\n",
    "GLOBAL_STD = np.load(\"data/global_std.npy\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((resize_size, resize_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=GLOBAL_MEAN, std=GLOBAL_STD)\n",
    "])\n",
    "\n",
    "data_path = 'data/data0/lsun/bedroom'\n",
    "batch_size = 16\n",
    "\n",
    "image_dataset = ImageFolder(root=data_path, transform=transform)\n",
    "image_dataset = Subset(image_dataset, torch.randperm(len(image_dataset))[:10000])\n",
    "train_dataloader = DataLoader(image_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for idx, batch in enumerate(train_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch[0][np.random.randint(0, batch_size)].permute(1, 2, 0))\n",
    "plt.title(\"Random transformed image.\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, size):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.dense_time = nn.Linear(out_channels, out_channels)\n",
    "        self.norm = nn.LayerNorm([out_channels, size, size])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_parameter = F.relu(self.conv1(x))\n",
    "        time_parameter = F.relu(self.dense_time(t))\n",
    "        time_parameter = time_parameter.view(-1, out_channels, 1, 1)\n",
    "        print(x_parameter.shape)\n",
    "        print(time_parameter.shape)\n",
    "        x_parameter = x_parameter * time_parameter\n",
    "        x_out = F.relu(self.conv2(x) + x_parameter)\n",
    "        x_out = self.norm(x_out)\n",
    "        return x_out\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block_down_1 = Block(in_channels=3, out_channels=128, size=resize_size)\n",
    "        self.block_down_2 = Block(in_channels=128, out_channels=128, size=8)\n",
    "        self.block_down_3 = Block(in_channels=128, out_channels=128, size=4)\n",
    "\n",
    "        self.block_up_1 = Block(in_channels=3, out_channels=128, size=4)\n",
    "        self.block_up_2 = Block(in_channels=128, out_channels=128, size=8)\n",
    "        self.block_up_3 = Block(in_channels=128, out_channels=128, size=resize_size)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mlp_t_initial = nn.Linear(1, 128)\n",
    "        self.norm_t_initial = nn.LayerNorm([128])\n",
    "\n",
    "        self.mlp_dense = nn.Linear(128, 128)\n",
    "        self.conv_out = nn.Conv2d(32, 3, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x_img, x_ts):\n",
    "\n",
    "        x_ts = self.mlp_t_initial(x_ts)\n",
    "        x_ts = self.norm_t_initial(x_ts)\n",
    "        x_ts = F.relu(x_ts)\n",
    "\n",
    "        x1 = self.block_down_1(x_img, x_ts)\n",
    "        x = self.maxpool(x1)\n",
    "        x2 = self.block_down_2(x, x_ts)\n",
    "        x = self.maxpool(x2)\n",
    "        x3 = self.block_down_3(x, x_ts)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = torch.cat((x, x_ts), dim=1)\n",
    "        x = self.mlp_dense(x)\n",
    "        x = nn.LayerNorm([128])\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 32, 4, 4)\n",
    "        \n",
    "        x = torch.cat((x, x3), dim=1)\n",
    "        x = self.block_up_1(x, x_ts)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        x = torch.cat((x, x2), dim=1)\n",
    "        x = self.block_up_2(x, x_ts)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        x = torch.cat((x, x1), dim=1)\n",
    "        x = self.block_up_3(x, x_ts)\n",
    "\n",
    "        \n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "model = UNet()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0008)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.full([batch_size, 1], 10, dtype=torch.float)\n",
    "model(batch[0], t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
